{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8442c22",
   "metadata": {},
   "source": [
    "## Transformando de dbz em mm/h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64177985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def numberOfDays(self, y, m):\n",
    "    leap = 0\n",
    "    if y% 400 == 0:\n",
    "        leap = 1\n",
    "    elif y % 100 == 0:\n",
    "        leap = 0\n",
    "    elif y% 4 == 0:\n",
    "        leap = 1\n",
    "    if m==2:\n",
    "        return 28 + leap\n",
    "    list = [1,3,5,7,8,10,12]\n",
    "    if m in list:\n",
    "        return 31\n",
    "    return 30\n",
    "print(numberOfDays(2020, 2))\n",
    "\n",
    "#dbz_file = sys.argv[1]\n",
    "#path_out = sys.argv[2]\n",
    "dbz_file = r'D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\dez_min\\01\\R13537439_201901010000.raw'\n",
    "path_out = r'D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\dez_min\\teste'\n",
    "\n",
    "def convert_to_dbz(dbz_file, path_out):\n",
    "    basename = os.path.basename(dbz_file)\n",
    "    #nx = 666\n",
    "    #ny = 666\n",
    "    #nx = 27\n",
    "    #ny = 29\n",
    "    nx = 500\n",
    "    ny = 500\n",
    "    dbz = np.fromfile(dbz_file, dtype=np.float32).reshape(ny, nx)\n",
    "    prec = np.full((ny, nx), -99.0, dtype=np.float32)\n",
    "\n",
    "    for x in range(nx):\n",
    "        for y in range(ny):\n",
    "            if dbz[y, x] != -99 and dbz[y, x] <= 36:\n",
    "                prec[y, x] = ((10**(dbz[y, x]/10))/200)**0.625\n",
    "            elif dbz[y, x] > 36:\n",
    "                prec[y, x] = ((10**(dbz[y, x]/10))/300)**0.714\n",
    "\n",
    "    prec_file = os.path.join(path_out, basename)\n",
    "    with open(prec_file, 'wb') as fn:  # Escrita do arquivo como binario\n",
    "        fn.write(prec)\n",
    "\n",
    "count_files = 0\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for filename in files:\n",
    "        count_files+=1\n",
    "\n",
    " \n",
    "directory = r'D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\dbz\\dez_min'\n",
    " \n",
    "# iterate over files in\n",
    "# that directory\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for filename in tqdm(files, total = count_files):\n",
    "        dbz_file = os.path.join(root, filename)\n",
    "        out_dir = os.path.join(r\"D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\mm_h\", root[-2:])\n",
    "        convert_to_dbz(dbz_file, out_dir)\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459c4614",
   "metadata": {},
   "source": [
    "## Transformando em acumulado horario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c8bc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "def numberOfDays(y, m):\n",
    "    leap = 0\n",
    "    if y% 400 == 0:\n",
    "        leap = 1\n",
    "    elif y % 100 == 0:\n",
    "        leap = 0\n",
    "    elif y% 4 == 0:\n",
    "        leap = 1\n",
    "    if m==2:\n",
    "        return 28 + leap\n",
    "    list = [1,3,5,7,8,10,12]\n",
    "    if m in list:\n",
    "        return 31\n",
    "    return 30\n",
    "print(numberOfDays(2020, 2))\n",
    "\n",
    "#NX = 27\n",
    "#NY = 29\n",
    "#NX = 37\n",
    "#NY = 36\n",
    "\n",
    "def create_hourly_acc(month):\n",
    "    NX = 500\n",
    "    NY = 500\n",
    "\n",
    "    dir_input = r\"D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\mm_h\\{}\".format(month)\n",
    "    dir_output = r\"D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\mm_h_acumulado\\{}\".format(month)\n",
    "    #dir_input = sys.argv[1]\n",
    "    #dir_output = sys.argv[2]\n",
    "    out = open('acum_prec_hourly.csv', 'w')\n",
    "    end_day = numberOfDays(2019,int(month))\n",
    "    start = datetime.strptime(\"2019{}0101\".format(month), \"%Y%m%d%H\") \n",
    "    end = datetime.strptime(\"2019{}{}23\".format(month,end_day), \"%Y%m%d%H\")\n",
    "    #start = datetime.strptime(sys.argv[3], \"%Y%m%d%H\")\n",
    "    #end = datetime.strptime(sys.argv[4], \"%Y%m%d%H\")\n",
    "\n",
    "    dict_hourly = {}\n",
    "    dict_daily = {}\n",
    "    datehour = start\n",
    "    #acum = np.full((NY, NX), 0, dtype=np.float32)\n",
    "\n",
    "    while datehour <= end:\n",
    "        acum = np.full((NY, NX), 0, dtype=np.float32)\n",
    "        pattern1 = datetime.strftime(datehour, \"*%Y%m%d%H00*.*\")\n",
    "        pattern2 = datetime.strftime(datehour - timedelta(hours=1), \"*%Y%m%d%H[!00]*.*\")\n",
    "        files = glob.glob(os.path.join(dir_input, pattern1)) + glob.glob(os.path.join(dir_input, pattern2))\n",
    "        nfiles = len(files)\n",
    "        for file in sorted(files):\n",
    "            print(file)\n",
    "            prec = np.fromfile(file.strip(), dtype=np.float32).reshape(NY, NX)\n",
    "            np.place(prec, prec==-99, 0.0)\n",
    "            np.place(prec, prec<1, 0.0)\n",
    "            acum = np.add(prec, acum)\n",
    "\n",
    "        if nfiles == 0:\n",
    "            datehour = datehour + timedelta(hours=1)\n",
    "            continue\n",
    "\n",
    "        acum = acum/nfiles\n",
    "\n",
    "        datehour_str = datetime.strftime(datehour, \"%Y%m%d%H\")\n",
    "        date_str = datetime.strftime(datehour, \"%Y%m%d\")\n",
    "\n",
    "        np.savetxt(os.path.join(dir_output, datehour_str+\"00.txt\"), acum, fmt='%03d')\n",
    "        print(datehour_str)\n",
    "\n",
    "    #    acum_campo = np.sum(acum)\n",
    "    #    dict_hourly[datehour_str] = acum_campo\n",
    "    #    if pattern1[9:11] == '00':\n",
    "    #        dict_daily[date_str] = 0\n",
    "    #    if not np.isnan(acum_campo):\n",
    "    #        dict_daily[date_str] = dict_daily[date_str] + acum_campo\n",
    "\n",
    "        #out.write(datehour_str+\",\"+str(dict[datehour_str])+\"\\n\")\n",
    "        datehour = datehour + timedelta(hours=1)\n",
    "\n",
    "\n",
    "    out.close()\n",
    "    #plt.plot(list(dict_daily.keys()), list(dict_daily.values()))\n",
    "    #plt.xticks(list(dict_daily.keys())[::2])\n",
    "    #plt.xticks(rotation=90)\n",
    "    #plt.show()\n",
    "\n",
    "for month in ['01','02','03','04','05','06','07','08','09','10','11','12']:\n",
    "    create_hourly_acc(month)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9491e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "arcpy.env.addOutputsToMap = False\n",
    "arcpy.env.workspace = r'D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\mm_h_acumulado_tifs'\n",
    "\n",
    "def generate_rain_points_shapefile(raster, out_shp_path):\n",
    "    #out_shape_path =  os.path.join(out_dir, 'data_'+ raster.split('.')[0] + '.shp')\n",
    "    raster_name = os.path.basename(raster.split('.')[0])\n",
    "    # Obtendo a data atraves do nome do arquivo\n",
    "    year = raster_name[:4]\n",
    "    month = raster_name[4:6]\n",
    "    day = raster_name[6:8]\n",
    "    hour = raster_name[8:10]\n",
    "    minute = raster_name[10:]\n",
    "    date = f'{day}/{month}/{year} {hour}:{minute}'\n",
    "    #date = f'{raster_name[:4]}-{raster_name[4:6]}-{raster_name[6:8]} {raster_name[8:10]}:{raster_name[10:]}'\n",
    "    \n",
    "    #Cortando o raster para o extent das ruas\n",
    "    raster = arcpy.management.Clip(raster, \"-46.83 -24 -46.36 -23.35\", \"tmp_raster.tif\", None, \"255\", \"NONE\", \"NO_MAINTAIN_EXTENT\")        \n",
    "    #Mantendo apenas as celulas com chuva>=1\n",
    "    raster = arcpy.ia.SetNull(raster, raster, \"VALUE = 0\")\n",
    "    if raster.maximum>0:\n",
    "        #Convertendo o raster para ponto\n",
    "        arcpy.conversion.RasterToPoint(raster, out_shp_path, \"Value\")\n",
    "        \n",
    "        #Adicionando o campo da data\n",
    "        arcpy.management.AddField(out_shp_path, 'data', 'DATE')\n",
    "\n",
    "        #Preenchendo o campo de data\n",
    "        with arcpy.da.UpdateCursor(out_shp_path, 'data') as cursor:\n",
    "            for row in cursor:\n",
    "                row[0] = date\n",
    "                cursor.updateRow(row)\n",
    "                \n",
    "rasters = arcpy.ListRasters()\n",
    "\n",
    "for raster in tqdm(rasters, total=len(rasters)):  \n",
    "    raster_name = raster.split('.')[0]\n",
    "    generate_rain_points_shapefile(raster, r'D:\\Trabalho\\faculdade\\TCC\\dados\\climaticos\\radar\\mm_h_acumulado_shps\\rain_{}.shp'.format(raster_name) )\n",
    "\n",
    "#Faz o merge de todos os shp\n",
    "#...\n",
    "#Muda o nome do campo de chuva\n",
    "#arcpy.management.AlterField(\"rain_radar_2019\", \"grid_code\", \"precipitacao\", \"precipitacao\", \"LONG\", 4, \"NULLABLE\", \"DO_NOT_CLEAR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
