{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera tabela que agrupa a lentidao por data e corredor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria tabela \"lentidao_por_data_e_corredor\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "arcpy.env.overwriteOutput = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abrindo dados de lentidão da CET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>corredor</th>\n",
       "      <th>tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>3592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>1567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/19 20:00</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>2101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data            corredor  tamanho\n",
       "0  1/1/19 19:30  Marginal Pinheiros     3592\n",
       "1  1/1/19 19:30  Marginal Pinheiros     1567\n",
       "2  1/1/19 20:00  Marginal Pinheiros     2101"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lentidao_cet = pd.read_csv(r\"D:\\Trabalho\\faculdade\\TCC\\dados\\lentidao\\baixados\\lentidaotrechos2019.csv\",sep=';',encoding='latin-1')[['data','corredor','tamanho']]\n",
    "lentidao_cet['corredor'] = lentidao_cet['corredor'].str.strip()\n",
    "lentidao_cet.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agrupando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>corredor</th>\n",
       "      <th>vias_correspondentes</th>\n",
       "      <th>tamanho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV ALCIDES SANGIRARDI</td>\n",
       "      <td>5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV DAS NACOES UNIDAS</td>\n",
       "      <td>5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV DRA RUTH CARDOSO</td>\n",
       "      <td>5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV ENG BILLINGS</td>\n",
       "      <td>5159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/19 19:30</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV GUIDO CALOI</td>\n",
       "      <td>5159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           data            corredor   vias_correspondentes  tamanho\n",
       "0  1/1/19 19:30  Marginal Pinheiros  AV ALCIDES SANGIRARDI     5159\n",
       "1  1/1/19 19:30  Marginal Pinheiros   AV DAS NACOES UNIDAS     5159\n",
       "2  1/1/19 19:30  Marginal Pinheiros    AV DRA RUTH CARDOSO     5159\n",
       "3  1/1/19 19:30  Marginal Pinheiros        AV ENG BILLINGS     5159\n",
       "4  1/1/19 19:30  Marginal Pinheiros         AV GUIDO CALOI     5159"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Agrupando os dados de lentidao por data e corredor\n",
    "correspondencia_lentidao = pd.read_csv(r\"D:\\Trabalho\\faculdade\\TCC\\outputs\\preprocessamento\\georreferenciamento\\correspondencia_lentidao_e_classeiviariacet_mod.txt\", sep=',').drop_duplicates(subset='vias_correspondentes',keep='first')\n",
    "lentidao_por_data_e_corredor = pd.merge(lentidao_cet,correspondencia_lentidao,on='corredor')\n",
    "lentidao_cet_groupby_data_e_corredor = lentidao_por_data_e_corredor.groupby(['data','corredor','vias_correspondentes']).agg('sum').reset_index().drop('corredor_id',axis=1)\n",
    "#lentidao_cet_groupby_data_e_corredor.to_csv(r\"D:\\Trabalho\\faculdade\\TCC\\outputs\\preprocessamento\\georreferenciamento\\lentidao_por_data_e_corredor.csv\")\n",
    "lentidao_cet_groupby_data_e_corredor.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria shp com arruamento válido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria tabela \"arruamento_valido\", com ruas que estão presentes tanto no shp de arruamento da CET quanto na base de lentidão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abrindo dados de correspondencia entre corredores de lentidão e shp de arruamento da CET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corredor_id</th>\n",
       "      <th>corredor</th>\n",
       "      <th>vias_correspondentes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV MARGINAL PINHEIROS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV ENG BILLINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Marginal Pinheiros</td>\n",
       "      <td>AV ALCIDES SANGIRARDI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   corredor_id            corredor   vias_correspondentes\n",
       "0            0  Marginal Pinheiros  AV MARGINAL PINHEIROS\n",
       "1            0  Marginal Pinheiros        AV ENG BILLINGS\n",
       "2            0  Marginal Pinheiros  AV ALCIDES SANGIRARDI"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Abrindo dados da correspondencia entre oc corredores de lentidao e as ruas da CET\n",
    "correspondencia_corredores = pd.read_csv(r\"D:\\Trabalho\\faculdade\\TCC\\outputs\\preprocessamento\\georreferenciamento\\correspondencia_lentidao_e_classeiviariacet_mod.txt\", sep=',').drop_duplicates(subset='vias_correspondentes',keep='first')\n",
    "correspondencia_corredores.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo variáveis importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_gdb = r'D:\\Trabalho\\faculdade\\TCC\\gis\\outputs.gdb'\n",
    "arruamento_gdb = r'D:\\Trabalho\\faculdade\\TCC\\gis\\arruamento.gdb'\n",
    "processamento_gdb = r'D:\\Trabalho\\faculdade\\TCC\\gis\\Analise.gdb'\n",
    "chuva_gdb = r'D:\\Trabalho\\faculdade\\TCC\\gis\\rain.gdb'\n",
    "alagamentos_gdb = r'D:\\Trabalho\\faculdade\\TCC\\gis\\alagamentos.gdb'\n",
    "preprocessamento_dir = r'D:\\Trabalho\\faculdade\\TCC\\outputs\\preprocessamento\\georreferenciamento'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gerando shp com as ruas validas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria cópia do shp de arruamento da CET\n",
    "shp_arruamento_cet = arcpy.management.CopyFeatures(os.path.join(arruamento_gdb, \"ruas_cet_sp\"), os.path.join(processamento_gdb, \"ruas_cet_sp_CopyFeatures\"), '', None, None, None)\n",
    "#Faz um dissolve do shp de arruamento da CET, para juntar ruas em apenas uma feature\n",
    "shp_arruamento_cet = arcpy.management.Dissolve(shp_arruamento_cet, os.path.join(processamento_gdb, \"arruamento_valido_tmp\"), \"cvc_nomelg\", None, \"MULTI_PART\", \"DISSOLVE_LINES\")\n",
    "\n",
    "#Função que remove os espaços em branco de uma string\n",
    "def remove_espacos_em_branco(string):\n",
    "    return ' '.join([x for x in string.split(' ') if len(x)>0])\n",
    "\n",
    "#Obtendo os nomes unicos de vias em que houve correspondecia entre o shp de arruamento e os dados de lentidão\n",
    "vias_nomes_unicos = list(correspondencia_corredores['vias_correspondentes'].unique())\n",
    "#Varrendo as linhas do shp de arruamento da CET\n",
    "with arcpy.da.UpdateCursor(shp_arruamento_cet,['cvc_nomelg'] ) as cursor:\n",
    "    for row in cursor:\n",
    "        row[0] = remove_espacos_em_branco(row[0])\n",
    "        #Se a via atual não é uma via em que houve match com os dados de lentidão, delete.\n",
    "        if row[0] not in vias_nomes_unicos:\n",
    "            cursor.deleteRow()\n",
    "        else:\n",
    "            #corrigindo o nome do campo\n",
    "            cursor.updateRow(row)\n",
    "del row\n",
    "#Altera o nome das colunas do shp de ruas válidas \n",
    "arcpy.management.AlterField(shp_arruamento_cet, \"cvc_nomelg\", \"via_cet\", \"via (CET)\", \"TEXT\", 180, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "# \"copia\" o shp de arruamento válido, para que o *OBJECTID seja restaurado, e assim seja possível realizar o join one to many. Nesse caso, copiei\n",
    "#Tanto para a gdb de processamento quanto para a de output. APararentemente o add join one to many so funciona quando as 2 tabelas estao na mesma gdb\n",
    "arcpy.conversion.FeatureClassToFeatureClass(shp_arruamento_cet, outputs_gdb, \"arruamento_valido\", '', 'via_cet \"via (CET)\" true true false 180 Text 0 0,First,#,arruamento_valido,via_cet,0,180;Shape_Length \"Shape_Length\" false true true 8 Double 0 0,First,#,arruamento_valido,Shape_Length,-1,-1', '')\n",
    "arruamento_valido_tmp = arcpy.conversion.FeatureClassToFeatureClass(shp_arruamento_cet, processamento_gdb, \"arruamento_valido\", '', 'via_cet \"via (CET)\" true true false 180 Text 0 0,First,#,arruamento_valido,via_cet,0,180;Shape_Length \"Shape_Length\" false true true 8 Double 0 0,First,#,arruamento_valido,Shape_Length,-1,-1', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juntando o shp de arruamento da CET com os dados de lentidão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "Failed to execute. Parameters are not valid.\nERROR 000728: Field lentidao_por_data_e_corredor_tmp_data does not exist within table\nERROR 000369: Invalid input field(s)\nFailed to execute (PairwiseDissolve).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "In  \u001b[0;34m[5]\u001b[0m:\nLine \u001b[0;34m9\u001b[0m:     arruamento_valido_e_lentidao = arcpy.analysis.PairwiseDissolve(ruas_validas_join_lentidao,  os.path.join(outputs_gdb, \u001b[33m\"\u001b[39;49;00m\u001b[33mjoin_enrich\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), \u001b[33m\"\u001b[39;49;00m\u001b[33mlentidao_por_data_e_corredor_tmp_corredor;lentidao_por_data_e_corredor_tmp_data\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mlentidao_por_data_e_corredor_tmp_lentidao MEAN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mMULTI_PART\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "File \u001b[0;34mD:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001b[0m, in \u001b[0;32mPairwiseDissolve\u001b[0m:\nLine \u001b[0;34m1139\u001b[0m:  \u001b[34mraise\u001b[39;49;00m e\n",
      "File \u001b[0;34mD:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\analysis.py\u001b[0m, in \u001b[0;32mPairwiseDissolve\u001b[0m:\nLine \u001b[0;34m1136\u001b[0m:  retval = convertArcObjectToPythonObject(gp.PairwiseDissolve_analysis(*gp_fixargs((in_features, out_feature_class, dissolve_field, statistics_fields, multi_part), \u001b[34mTrue\u001b[39;49;00m)))\n",
      "File \u001b[0;34mD:\\Program Files\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m, in \u001b[0;32m<lambda>\u001b[0m:\nLine \u001b[0;34m512\u001b[0m:   \u001b[34mreturn\u001b[39;49;00m \u001b[34mlambda\u001b[39;49;00m *args: val(*gp_fixargs(args, \u001b[34mTrue\u001b[39;49;00m))\n",
      "\u001b[0;31mExecuteError\u001b[0m: Failed to execute. Parameters are not valid.\nERROR 000728: Field lentidao_por_data_e_corredor_tmp_data does not exist within table\nERROR 000369: Invalid input field(s)\nFailed to execute (PairwiseDissolve).\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "#Exporta o csv de lentidao_por_data_e_corredor como uma tabela do ArcGIS para que o join possa ser feito\n",
    "tabela_lentidao_por_data_e_corredor = arcpy.conversion.TableToTable(os.path.join(preprocessamento_dir,\"lentidao_por_data_e_corredor.csv\"),processamento_gdb , \"lentidao_por_data_e_corredor_tmp\", '', 'data \"data\" true true false 8 Date 0 0,First,#,lentidao_por_data_e_corredor.csv,data,-1,-1;corredor \"corredor\" true true false 8000 Text 0 0,First,#,lentidao_por_data_e_corredor.csv,corredor,0,8000;via_cet \"via (CET)\" true true false 8000 Text 0 0,First,#,lentidao_por_data_e_corredor.csv,vias_correspondentes,0,8000;lentidao \"lentidao\" true true false 4 Long 0 0,First,#,lentidao_por_data_e_corredor.csv,tamanho,-1,-1', '')\n",
    "#Faz um join (temporario) entre o shp de arruamento valido e os dados de lentidão por data e corredor\n",
    "arcpy.management.AddJoin(arruamento_valido_tmp, \"via_cet\", tabela_lentidao_por_data_e_corredor, \"via_cet\", \"KEEP_COMMON\", \"NO_INDEX_JOIN_FIELDS\")\n",
    "#Copiando a feature para fazer com que o join seja permanente\n",
    "ruas_validas_join_lentidao = arcpy.management.CopyFeatures(arruamento_valido_tmp,os.path.join(processamento_gdb, 'join_lentidao_tmp'), '', None, None, None)\n",
    "#Dissolvendo o shp com base no corredor (de lentidao). Nesse processo, calculo a lentidao media.\n",
    "arruamento_valido_e_lentidao = arcpy.analysis.PairwiseDissolve(ruas_validas_join_lentidao,  os.path.join(outputs_gdb, \"arruamento_valido_e_lentidao\"), \"lentidao_por_data_e_corredor_tmp_corredor;lentidao_por_data_e_corredor_tmp_data\", \"lentidao_por_data_e_corredor_tmp_lentidao MEAN\", \"MULTI_PART\")\n",
    "#Alterando os nomes da coluna de lentidao\n",
    "arcpy.management.AlterField(\"arruamento_v_join_lent_Dissolve\", \"MEAN_lentidao_por_data_e_corredor_tmp_lentidao\", '', \"lentidao\", \"TEXT\", 8000, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "#Alterando os nomes da coluna de data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando dados de chuva (radar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shp_arruamento_valido_e_lentidao = os.path.join(outputs_gdb, 'arruamento_valido_e_lentidao')\n",
    "shp_chuva_radar = os.path.join(chuva_gdb, 'rain_radar_2019')\n",
    "\n",
    "#Faz o join da chuva com lentidao com base na distancia e horario\n",
    "arruamento_lentidao_chuva = arcpy.gapro.JoinFeatures(shp_arruamento_valido_e_lentidao, shp_chuva_radar, os.path.join(processamento_gdb, \"arruamento_valido_lentidao_chuva\"), \"JOIN_ONE_TO_MANY\", \"NEAR\", \"1 Kilometers\", \"NEAR_AFTER\", \"3 Hours\", None, None, '', None)\n",
    "#Remove colunas desnecessárias\n",
    "arcpy.management.DeleteField(arruamento_lentidao_chuva, \"OBJECTID;pointid;DATE1;join_OBJECTID\", \"DELETE_FIELDS\")\n",
    "\n",
    "#Mudando o nome de algumas colunas\n",
    "arcpy.management.AlterField(arruamento_lentidao_chuva, \"lentidao_por_data_e_corredor_tmp_data\", \"data_medicao\", \"data medicao\", \"DATE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(arruamento_lentidao_chuva, \"lentidao_por_data_e_corredor_tmp_corredor\", \"corredor\", \"corredor\", \"TEXT\", 10485758, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(arruamento_lentidao_chuva, \"data\", \"data_chuva\", \"data chuva\", \"DATE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "\n",
    "#Dissolvendo com base no corredor e na data da medição da lentidão\n",
    "arruamento_lentidao_chuva_dissolve = arcpy.analysis.PairwiseDissolve(arruamento_lentidao_chuva, os.path.join(outputs_gdb, 'join_chuva'), \"corredor;data_lentidao\", \"lentidao MEAN;precipitacao SUM\", \"MULTI_PART\")\n",
    "#mudando nome de algumas colunas\n",
    "arcpy.management.AlterField(arruamento_lentidao_chuva_dissolve, \"MEAN_lentidao\", \"lentidao\", \"lentidao\", \"DOUBLE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(arruamento_lentidao_chuva_dissolve, \"SUM_precipitacao\", \"precipitacao\", \"precipitacao\", \"DOUBLE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando dados de alagamento "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando shape de alagamentos 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alagamentos_2019_csv = os.path.join(r'D:\\Trabalho\\faculdade\\TCC\\dados\\alagamentos\\2019','ocorrencias_2019.csv')\n",
    "#Criando fc a patir do csv\n",
    "alagamentos_2019_tmp = arcpy.management.XYTableToPoint(alagamentos_2019_csv, os.path.join(processamento_gdb, 'alagamentos_2019_tmp'), \"LONG,N,16,6\", \"LAT,N,16,6\", None, 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision')\n",
    "\n",
    "#Alterando o nome de algumas colunas\n",
    "arcpy.management.AlterField(alagamentos_2019_tmp, \"DATA_D\", \"dia\", \"dia\", \"DATE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(alagamentos_2019_tmp, \"H_INICIO_C_254\", \"hora_inicio\", \"hora inicio\", \"TEXT\", 8000, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(alagamentos_2019_tmp, \"H_FIM_C_254\", \"hora_fim\", \"hora fim\", \"TEXT\", 8000, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(alagamentos_2019_tmp, \"DUR_H_N_7_2\", \"duracao\", \"duracao\", \"DOUBLE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "#Criando colunas de data de inicio e fim\n",
    "arcpy.management.AddField(alagamentos_2019_tmp, \"data_inicio\", \"DATE\", None, None, None, \"data inicio\", \"NULLABLE\", \"NON_REQUIRED\", '')\n",
    "arcpy.management.AddField(alagamentos_2019_tmp, \"data_fim\", \"DATE\", None, None, None, \"data fim\", \"NULLABLE\", \"NON_REQUIRED\", '')\n",
    "\n",
    "#Populando os campos de data de inicio e fim\n",
    "with arcpy.da.UpdateCursor('ocorrencias_2019_tmp',['dia','hora_inicio','hora_fim','data_inicio','data_fim']) as cursor:\n",
    "    for row in cursor:\n",
    "        ano = row[0].year\n",
    "        mes = row[0].month\n",
    "        dia = row[0].day\n",
    "        hora_inicio = row[1]\n",
    "        hora_fim = row[2]\n",
    "        data_inicio = f'{dia}/{mes}/{ano} {hora_inicio}'\n",
    "        data_fim = f'{dia}/{mes}/{ano} {hora_fim}'\n",
    "        if None in [ano,mes,dia,hora_inicio,hora_fim]:\n",
    "            row[3] = None\n",
    "            row[4] = None\n",
    "        else:\n",
    "        #Atualizando as colunas\n",
    "            row[3] = data_inicio\n",
    "            row[4] = data_fim\n",
    "            cursor.updateRow(row)\n",
    "            \n",
    "#Reprojetando\n",
    "alagamentos_2019_tmp_proj = arcpy.management.Project(alagamentos_2019_tmp, 'alagamentos_2019_tmp_project', 'PROJCS[\"SIRGAS_2000_UTM_Zone_23S\",GEOGCS[\"GCS_SIRGAS_2000\",DATUM[\"D_SIRGAS_2000\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",10000000.0],PARAMETER[\"Central_Meridian\",-45.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]', \"SIRGAS_2000_To_WGS_1984_1\", 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \"NO_PRESERVE_SHAPE\", None, \"NO_VERTICAL\")\n",
    "#Exportando apenas as colunas necessárias\n",
    "alagamentos_2019 = arcpy.conversion.FeatureClassToFeatureClass(alagamentos_2019_tmp_proj, r\"D:\\Trabalho\\faculdade\\TCC\\gis\\alagamentos.gdb\", \"alagamentos_2019\", '', f'data_inicio \"data inicio\" true true false 8 Date 0 0,First,#,{alagamentos_2019_tmp_proj},data_inicio,-1,-1;data_fim \"data fim\" true true false 8 Date 0 0,First,#,{alagamentos_2019_tmp_proj},data_fim,-1,-1;duracao \"duracao\" true true false 8 Double 0 0,First,#,{alagamentos_2019_tmp_proj},duracao,-1,-1', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Juntando shape de alagementos 2019 com shape de lentidao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo join dos dados de lentidao com os de alagamento\n",
    "join_alagamentos_tmp = arcpy.gapro.JoinFeatures(os.path.join(processamento_gdb,\"arruamento_valido_e_lentidao\"), alagamentos_2019,os.path.join(outputs_gdb,'join_alagamentos'), \"JOIN_ONE_TO_MANY\", \"NEAR\", \"500 Meters\", \"DURING\", None, None, None, '', None)\n",
    "\n",
    "#Inserindo campo de duracao do alagamento ate a data da medicao da lentidao\n",
    "arcpy.management.AddField(join_alagamentos_tmp, \"duracao_alagamento\", \"FLOAT\", None, None, None, \"duracao alagamento\", \"NULLABLE\", \"NON_REQUIRED\", '')\n",
    "\n",
    "#Populando o campo de duracao do alagamento\n",
    "\n",
    "with arcpy.da.UpdateCursor(join_alagamentos_tmp, ['data_inicio','DATE','duracao_alagamento']) as cursor:\n",
    "    for row in cursor:\n",
    "        data_inicio_alagamento = row[0]\n",
    "        data_medicao_lentidao = row[1]\n",
    "        #tempo alagado ate a data da medição da lentidao\n",
    "        duracao = (data_medicao_lentidao - data_inicio_alagamento)\n",
    "        dias, segundos = duracao.days, duracao.seconds\n",
    "        horas = dias * 24 + segundos // 3600\n",
    "        minutos = (segundos % 3600) // 60\n",
    "        duracao_alagamento = round(horas + minutos/60, 3)\n",
    "        row[2] = duracao_alagamento\n",
    "        cursor.updateRow(row)\n",
    "\n",
    "#Dissolvendo com base na data de medição de lentidão e no corredor\n",
    "join_alagamentos = arcpy.analysis.PairwiseDissolve(join_alagamentos_tmp, os.path.join(outputs_gdb,'join_alagamentos'), \"DATE;lentidao_por_data_e_corredor_tmp_corredor\", \"lentidao MEAN;duracao_alagamento SUM;OBJECTID1 COUNT\", \"MULTI_PART\")\n",
    "\n",
    "#Alterando os nomes das colunas\n",
    "arcpy.management.AlterField(join_alagamentos, \"DATE\", \"data_medicao\", \"data medicao\", \"DATE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(join_alagamentos, \"MEAN_lentidao\", \"lentidao\", \"lentidao\", \"DOUBLE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(join_alagamentos, \"SUM_duracao_alagamento\", \"soma_duracoes_alagamentos\", \"soma duracoes alagementos\", \"DOUBLE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(join_alagamentos, \"COUNT_OBJECTID1\", \"quantidade_alagamentos\", \"quantidade alagamentos\", \"LONG\", 4, \"NULLABLE\", \"DO_NOT_CLEAR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Fazer um join do shape e os dados de lentidao 2019, como base na distancia enter o ponto de alagamento e o corredor (300m) e o horário do alagamento e medição da lentidão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicionando dados de acidente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gerando e limpando dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "#Gerando shp a partir do csv de acidentes\n",
    "acidentes_csv = r\"D:\\Trabalho\\faculdade\\TCC\\dados\\acidentes\\acidentes_2014a2021.csv\"\n",
    "shp_acidentes = arcpy.management.XYTableToPoint(acidentes_csv, os.path.join(processamento_gdb,'acidentes_tmp'), \"LONG_(GEO)\", \"LAT_(GEO)\", None, 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]];-400 -400 1000000000;-100000 10000;-100000 10000;8.98315284119521E-09;0.001;0.001;IsHighPrecision')\n",
    "\n",
    "#Adicionando campo vazio de data\n",
    "arcpy.management.AddField(shp_acidentes, \"data\", \"DATE\", None, None, None, '', \"NULLABLE\", \"NON_REQUIRED\", '')\n",
    "with arcpy.da.UpdateCursor(shp_acidentes,['Data_do_Acidente', 'Hora_do_Acidente', 'data_acidente']) as cursor:\n",
    "    for row in cursor:\n",
    "        dia = row[0]\n",
    "        hora = row[1]\n",
    "        if not hora:\n",
    "            row[2] = None\n",
    "        else:\n",
    "            row[2] = f'{dia.strftime(r\"%d/%m/%Y\")} {hora[:5]}'\n",
    "        \n",
    "        cursor.updateRow(row)\n",
    "#Removendo colunas desnecessárias\n",
    "arcpy.management.DeleteField(shp_acidentes, \"Field1;Administração;Jurisdição;Logradouro;Mês_do_Acidente;Hora_do_Acidente;ID;Município;Região_Administrativa;Dia_do_Acidente;Turno;Ano_do_Acidente;Ano_Mês_do_Acidente;Conservação;Data_do_Acidente;Iluminação;Superfície_da_via;Tipo_de_pista;LAT__GEO_;LONG__GEO_\", \"DELETE_FIELDS\")\n",
    "#Projetando e salvando na pasta correta\n",
    "arcpy.management.Project(shp_acidentes, os.path.join(acidentes_gdb,'acidentes'), 'PROJCS[\"SIRGAS_2000_UTM_Zone_23S\",GEOGCS[\"GCS_SIRGAS_2000\",DATUM[\"D_SIRGAS_2000\",SPHEROID[\"GRS_1980\",6378137.0,298.257222101]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"False_Easting\",500000.0],PARAMETER[\"False_Northing\",10000000.0],PARAMETER[\"Central_Meridian\",-45.0],PARAMETER[\"Scale_Factor\",0.9996],PARAMETER[\"Latitude_Of_Origin\",0.0],UNIT[\"Meter\",1.0]]', \"SIRGAS_2000_To_WGS_1984_1\", 'GEOGCS[\"GCS_WGS_1984\",DATUM[\"D_WGS_1984\",SPHEROID[\"WGS_1984\",6378137.0,298.257223563]],PRIMEM[\"Greenwich\",0.0],UNIT[\"Degree\",0.0174532925199433]]', \"NO_PRESERVE_SHAPE\", None, \"NO_VERTICAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Juntando com dado de lentidao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_acidentes_tmp = arcpy.gapro.JoinFeatures(os.path.join(outputs_gdb,'arruamento_valid_e_lentidao'), os.path.join(acidentes_gdb,'acidentes'), os.path.join(processamento_gdb,'join_acidentes_tmp'), \"JOIN_ONE_TO_MANY\", \"NEAR\", \"300 Meters\", \"NEAR_AFTER\", \"1 Hours\", None, None, '', None)\n",
    "#Dissolvendo com base na data de medição da lentidao e corredor \n",
    "join_acidentes = arcpy.analysis.PairwiseDissolve(join_acidentes_tmp, os.path.join(outputs_gdb,'join_acidentes'), \"lentidao_por_data_e_corredor_tmp_data;lentidao_por_data_e_corredor_tmp_corredor\", \"lentidao MEAN;OBJECTID1 COUNT\", \"MULTI_PART\")\n",
    "\n",
    "#ALterando nome das colunas\n",
    "arcpy.management.AlterField(join_alagamentos, \"MEAN_lentidao\", \"lentidao\", \"lentidao\", \"DOUBLE\", 8, \"NULLABLE\", \"DO_NOT_CLEAR\")\n",
    "arcpy.management.AlterField(join_alagamentos, \"COUNT_OBJECTID1\", \"quantidade_acidentes\", \"quantidade acidentes\", \"LONG\", 4, \"NULLABLE\", \"DO_NOT_CLEAR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "file_extension": ".py",
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
